# Creating our Positive definite matrix
SIGMA = rnorm(p^2, 1, 1)
dim(SIGMA) = c(p,p)
SIGMA = 0.5*(SIGMA + t(SIGMA))
SIGMA = SIGMA * t(SIGMA)
SIGMA = SIGMA + p*diag(p)
## Problem Set 3 Question 2
##
##
## In this question we conduct a Monte Carlo study in R that compares the
## performance of different methods that adjust for multiple comparisons.
##
## This file is part of a set of files consisting of:
## ps3_q1.R, ps3_q2.R, ps3_q3.R, ps3.Rmd, and ps3.pdf
##
## Author: Israel Diego (israeldi@umich.edu)
## Updated: November 19, 2018
rm(list = ls())
library(MASS)
set.seed(42)
# QUESTION 2A -----------------------------------------------------------------
mc_rep = 100                   # Simulation replications
n = 1000                       # Sample size we are studying
p = 100                        # Number of predictors
k = 10                         # NumBetas = 1
mu = matrix(0, nrow = p)       # Average of our X matrix
sigma2 = 3                     # Variance of Y
# Creating our Positive definite matrix
SIGMA = rnorm(p^2, 1, 1)
dim(SIGMA) = c(p,p)
SIGMA = 0.5*(SIGMA + t(SIGMA))
SIGMA = SIGMA * t(SIGMA)
SIGMA = SIGMA + p*diag(p)
# Randomly generated multivariate normal
X = mvrnorm(n, mu,  SIGMA, empirical = FALSE, EISPACK = FALSE)
beta = c( matrix(1, nrow = k), matrix(0, nrow = p - k))
# Initializing matrix of p_values to be filled when we call MonteCarloPValues
p_values_m = matrix(0, nrow = p, ncol = mc_rep)
# MonteCarlo Function the returns P values
MonteCarloPValues = function(X, beta, sigma2, mc_rep)
{
n = dim(X)[1]
p = dim(X)[2]
p_values_m = matrix(0, nrow = p, ncol = mc_rep)
# QR Decomposition
QR = qr(X)
for (i in 1:mc_rep)
{
# Set seed for testing
if (FALSE)
{
set.seed(42)
}
# Generate Y from X, beta, and sigma2
Y = rnorm(n, mean = X %*% beta, sd = sigma2 * diag(p))
# Calculate betaHat from QR decomposition
betaHat = solve(qr.R(QR), t(qr.Q(QR)) %*% Y )
# Calculate Yhat from betaHat
Yhat = X %*% betaHat
# Calculate sigmaHat squared
sigmaHat2 = (1 / (n - p)) * sum( (Y - Yhat) ^ 2)
# Calculate Variance of our betas, getting the diagonal of Var/Cov matrix
VAR_BetaHat = diag(sigmaHat2[1] * chol2inv( qr.R(QR) ))
# Calculate Z-Score
Z = betaHat / sqrt(VAR_BetaHat)
# p_values
p_values = 2 * (1 - pnorm(abs(Z), 0, 1, lower.tail = TRUE))
# Add p_values vector to our matrix of p_values for each Monte Carlo trial
p_values_m[, i] = p_values
}
p_values_m
}
# Testing phase, check if p-values correspond
if (FALSE)
{
set.seed(42)
# Y matrix for testing
testY = rnorm(n, mean = X %*% beta, sd = sigma2 * diag(p))
testLm = summary(lm(testY ~ 0 + X))
p_values_m = MonteCarloPValues(X, beta, sigma2, mc_rep)
p_values_m[,1]
View(cbind(p_values_m[,1] ,testLm$coefficients[,4]))
}
# QUESTION 2B -----------------------------------------------------------------
R = chol(SIGMA)
X = rnorm(n * p)
dim(X) = c(n, p)
M = X %*% R
p_values_m = MonteCarloPValues(M, beta, sigma2, mc_rep)
# QUESTION 2C -----------------------------------------------------------------
# Assumes NumBetas != 0 are at the first k rows of our data frame
evaluate = function(p_values_m, alpha, numBetasNotEqual0)
{
# Initializers
k = numBetasNotEqual0 # numBetas != 0
numCols = ncol(p_values_m)
numBetasEqual0 = nrow(p_values_m) - k
testsList = c("FWER", "FDR", "sensitivity", "specificity")
# Set up our matrix to collect multiple Tests for each column
multipleTests = data.frame(matrix(nrow = length(testsList), ncol = numCols))
row.names(multipleTests) = testsList
# Look through each column of our p-values
for (j in 1:numCols)
{
# Collect the jth column of p_values
p_values = p_values_m[,j]
# Collect total number of significant p_values
rejections = which(p_values < alpha)
# Collecting FN, FP, TN, and TP
FalsePos = sum(rejections > k)
TruePos = sum(rejections <= k)
TrueNeg = numBetasEqual0 - FalsePos
# family-wise error
FWER = any(rejections > k)
# false discovery proportion
FDR = FalsePos / (FalsePos + TruePos)
# sensitivity
sensitivity = TruePos / k
# specifity
specificity = TrueNeg / (TrueNeg + FalsePos)
# Collect results for column in our multipleTests matrix
multipleTests["FWER", j] = FWER
multipleTests["FDR", j] = FDR
multipleTests["sensitivity", j] = sensitivity
multipleTests["specificity", j] = specificity
}
# Take average for each test
multipleTests = rowMeans(multipleTests)
}
# QUESTION 2D -----------------------------------------------------------------
### Perform p-value adjustments and add to data frame
correctionsList = c("bonferroni", "holm", "BH", "BY")
testsList = c("FWER", "FDR", "sensitivity", "specificity")
alpha = 0.05
# Set up our matrix to collect multiple Tests for each column
multipleTests = data.frame(matrix(
nrow = length(testsList),
ncol = length(correctionsList)))
row.names(multipleTests) = testsList
colnames(multipleTests) = correctionsList
# Loop through each method from our Corrections list and produce a table with
# the output from our evaluate function for each correction method
for (methodName in correctionsList)
{
# Initializing p_values matrix
p_values = matrix(nrow = nrow(p_values_m), ncol = ncol(p_values_m))
# adjusting p_values given the method
p_values = as.matrix(p.adjust(p_values_m, method = methodName))
dim(p_values) = c(p, mc_rep)
# Run tests with our evaluate function
test = evaluate(p_values, alpha, k)
# Update column of multipleTests matrix with results from evaluate()
multipleTests[, methodName] = test
}
# Calculate Unadjusted P-Values
multipleTests[,"Unadjusted_Pvals"] = evaluate(p_values_m, alpha, k)
multipleTests = round(multipleTests, digits = 3)
# Add column containing the tests we performed
multipleTests["Tests",] = c(correctionsList, "Unadjusted")
multipleTests = as.data.frame(t(multipleTests))
# Reorder rows to be displayed in bar graphs
multipleTests = multipleTests[c("Unadjusted_Pvals",correctionsList),]
multipleTests$Tests = factor(multipleTests$Tests,
levels = multipleTests$Tests)
# QUESTION 2E -----------------------------------------------------------------
library(ggplot2)
library(gridExtra)
# PLOTS IN RMARKDOWN ##
dim(p_values_m[-c(1:10),])
View(multipleTests)
View(p_values_m)
dim(as.vector(p_values_m[-c(1:10),]))
length(as.vector(p_values_m[-c(1:10),]))
ggplot(p_values_m[-c(1:10),], aes(x = as.vector(p_values_m[-c(1:10),]))) +
geom_density(aes(group = ind, colour = ind))
ggplot(p_values_m[-c(1:10),], aes(x = p_values_m[-c(1:10),])) +
geom_density(aes(group = ind, colour = ind))
# PLOTS IN RMARKDOWN ##
p_values_m %>%
p_values_m[-c(1:10),]
# PLOTS IN RMARKDOWN ##
p_values_m %>%
p_values_m[-c(1:10),]
# PLOTS IN RMARKDOWN ##
p_values_m[-c(1:10),] %>%
dim(.) = c(9000,1)
# PLOTS IN RMARKDOWN ##
p_values_m[-c(1:10),] %>%
dim() = c(9000,1)
# PLOTS IN RMARKDOWN ##
p_values_m[-c(1:10),] %>%
c(9000,1)
# PLOTS IN RMARKDOWN ##
test = p_values_m[-c(1:10),] %>% c(9000,1)
dim(test)
length(test)
View(test)
# PLOTS IN RMARKDOWN ##
test = data.frame(p_values_m[-c(1:10),] %>% c(9000,1))
View(test)
colnames(test)[1] = "p_values"
test = data.frame(p_values_m[-c(1:10),] %>% c(9000,1))
colnames(test)[1] = "p_values"
View(test)
ggplot(test, aes(x = p_values)) +
geom_density(aes(group = ind, colour = ind))
ggplot(test, aes(x = p_values)) +
geom_density()
View(p_values)
View(test)
cap = '**Figure 2.** Estimated average annual electricity usage in khw/home for
each of 10 census divisions.'
kwh %>%
arrange( desc(est) ) %>%
mutate( div = factor(as.character(division), as.character(division) ) ) %>%
ggplot( aes(x = div, y = est) ) +
geom_point() +
geom_errorbar( aes(ymin = lwr, ymax = upr)) +
coord_flip() +
theme_bw() +
ylab('kwh/home') +
xlab('')
source('./ps3_q1.R')
cap = '**Figure 1.** Estimated percent of homes within each census division
with major wall type of stucco.'
p_stucco %>%
arrange( desc(p_stucco) ) %>%
mutate( Division =
factor( as.character(division),  as.character(division) )
) %>%
ggplot( aes( x = Division, y = 100*p_stucco) ) +
geom_col( fill = 'navy' ) +
geom_errorbar( aes( ymin = 100*lwr, ymax = 100*upr),
col = 'darkslategrey') +
theme_bw() +
ylab('% Stucco Homes') +
xlab('Census Division') +
theme( axis.text.x = element_text(size = 8, angle = 90))
ggplot(test, aes(y = p_values)) +
geom_density()
## Problem Set 3 Question 2
##
##
## In this question we conduct a Monte Carlo study in R that compares the
## performance of different methods that adjust for multiple comparisons.
##
## This file is part of a set of files consisting of:
## ps3_q1.R, ps3_q2.R, ps3_q3.R, ps3.Rmd, and ps3.pdf
##
## Author: Israel Diego (israeldi@umich.edu)
## Updated: November 19, 2018
rm(list = ls())
library(MASS)
set.seed(42)
# QUESTION 2A -----------------------------------------------------------------
mc_rep = 100                   # Simulation replications
n = 1000                       # Sample size we are studying
p = 100                        # Number of predictors
k = 10                         # NumBetas = 1
mu = matrix(0, nrow = p)       # Average of our X matrix
sigma2 = 3                     # Variance of Y
# Creating our Positive definite matrix
SIGMA = rnorm(p^2, 1, 1)
dim(SIGMA) = c(p,p)
SIGMA = 0.5*(SIGMA + t(SIGMA))
SIGMA = SIGMA * t(SIGMA)
SIGMA = SIGMA + p*diag(p)
# Randomly generated multivariate normal
X = mvrnorm(n, mu,  SIGMA, empirical = FALSE, EISPACK = FALSE)
beta = c( matrix(1, nrow = k), matrix(0, nrow = p - k))
# Initializing matrix of p_values to be filled when we call MonteCarloPValues
p_values_m = matrix(0, nrow = p, ncol = mc_rep)
# MonteCarlo Function the returns P values
MonteCarloPValues = function(X, beta, sigma2, mc_rep)
{
n = dim(X)[1]
p = dim(X)[2]
p_values_m = matrix(0, nrow = p, ncol = mc_rep)
# QR Decomposition
QR = qr(X)
for (i in 1:mc_rep)
{
# Set seed for testing
if (FALSE)
{
set.seed(42)
}
# Generate Y from X, beta, and sigma2
Y = rnorm(n, mean = X %*% beta, sd = sigma2 * diag(p))
# Calculate betaHat from QR decomposition
betaHat = solve(qr.R(QR), t(qr.Q(QR)) %*% Y )
# Calculate Yhat from betaHat
Yhat = X %*% betaHat
# Calculate sigmaHat squared
sigmaHat2 = (1 / (n - p)) * sum( (Y - Yhat) ^ 2)
# Calculate Variance of our betas, getting the diagonal of Var/Cov matrix
VAR_BetaHat = diag(sigmaHat2[1] * chol2inv( qr.R(QR) ))
# Calculate Z-Score
Z = betaHat / sqrt(VAR_BetaHat)
# p_values
p_values = 2 * (1 - pnorm(abs(Z), 0, 1, lower.tail = TRUE))
# Add p_values vector to our matrix of p_values for each Monte Carlo trial
p_values_m[, i] = p_values
}
p_values_m
}
# Testing phase, check if p-values correspond
if (FALSE)
{
set.seed(42)
# Y matrix for testing
testY = rnorm(n, mean = X %*% beta, sd = sigma2 * diag(p))
testLm = summary(lm(testY ~ 0 + X))
p_values_m = MonteCarloPValues(X, beta, sigma2, mc_rep)
p_values_m[,1]
View(cbind(p_values_m[,1] ,testLm$coefficients[,4]))
}
# QUESTION 2B -----------------------------------------------------------------
R = chol(SIGMA)
X = rnorm(n * p)
dim(X) = c(n, p)
M = X %*% R
p_values_m = MonteCarloPValues(M, beta, sigma2, mc_rep)
# QUESTION 2C -----------------------------------------------------------------
# Assumes NumBetas != 0 are at the first k rows of our data frame
evaluate = function(p_values_m, alpha, numBetasNotEqual0)
{
# Initializers
k = numBetasNotEqual0 # numBetas != 0
numCols = ncol(p_values_m)
numBetasEqual0 = nrow(p_values_m) - k
testsList = c("FWER", "FDR", "sensitivity", "specificity")
# Set up our matrix to collect multiple Tests for each column
multipleTests = data.frame(matrix(nrow = length(testsList), ncol = numCols))
row.names(multipleTests) = testsList
# Look through each column of our p-values
for (j in 1:numCols)
{
# Collect the jth column of p_values
p_values = p_values_m[,j]
# Collect total number of significant p_values
rejections = which(p_values < alpha)
# Collecting FN, FP, TN, and TP
FalsePos = sum(rejections > k)
TruePos = sum(rejections <= k)
TrueNeg = numBetasEqual0 - FalsePos
# family-wise error
FWER = any(rejections > k)
# false discovery proportion
FDR = FalsePos / (FalsePos + TruePos)
# sensitivity
sensitivity = TruePos / k
# specifity
specificity = TrueNeg / (TrueNeg + FalsePos)
# Collect results for column in our multipleTests matrix
multipleTests["FWER", j] = FWER
multipleTests["FDR", j] = FDR
multipleTests["sensitivity", j] = sensitivity
multipleTests["specificity", j] = specificity
}
# Take average for each test
multipleTests = rowMeans(multipleTests)
}
# QUESTION 2D -----------------------------------------------------------------
### Perform p-value adjustments and add to data frame
correctionsList = c("bonferroni", "holm", "BH", "BY")
testsList = c("FWER", "FDR", "sensitivity", "specificity")
alpha = 0.05
# Set up our matrix to collect multiple Tests for each column
multipleTests = data.frame(matrix(
nrow = length(testsList),
ncol = length(correctionsList)))
row.names(multipleTests) = testsList
colnames(multipleTests) = correctionsList
# Loop through each method from our Corrections list and produce a table with
# the output from our evaluate function for each correction method
for (methodName in correctionsList)
{
# Initializing p_values matrix
p_values = matrix(nrow = nrow(p_values_m), ncol = ncol(p_values_m))
# adjusting p_values given the method
p_values = as.matrix(p.adjust(p_values_m, method = methodName))
dim(p_values) = c(p, mc_rep)
# Run tests with our evaluate function
test = evaluate(p_values, alpha, k)
# Update column of multipleTests matrix with results from evaluate()
multipleTests[, methodName] = test
}
# Calculate Unadjusted P-Values
multipleTests[,"Unadjusted_Pvals"] = evaluate(p_values_m, alpha, k)
multipleTests = round(multipleTests, digits = 3)
# Add column containing the tests we performed
multipleTests["Tests",] = c(correctionsList, "Unadjusted")
multipleTests = as.data.frame(t(multipleTests))
# Reorder rows to be displayed in bar graphs
multipleTests = multipleTests[c("Unadjusted_Pvals",correctionsList),]
multipleTests$Tests = factor(multipleTests$Tests,
levels = multipleTests$Tests)
# QUESTION 2E -----------------------------------------------------------------
library(ggplot2)
library(gridExtra)
# PLOTS IN RMARKDOWN ##
test = data.frame(p_values_m[-c(1:10),] %>% c(9000,1))
colnames(test)[1] = "p_values"
ggplot(test, aes(y = p_values)) +
geom_density()
ggplot(test, aes(x = 0:1,y = p_values)) +
geom_density()
ggplot(test, aes(x = p_values)) + geom_histogram()
test[-c(9001,9002),]
test = test[-c(9001,9002),]
ggplot(test, aes(x = p_values)) + geom_histogram()
test = data.frame(test[-c(9001,9002),])
test = data.frame(p_values_m[-c(1:10),] %>% c(9000,1))
colnames(test)[1] = "p_values"
test = data.frame(test[-c(9001,9002),])
ggplot(test, aes(x = p_values)) + geom_histogram()
View(X)
View(test)
test = data.frame(p_values_m[-c(1:10),] %>% c(9000,1))
colnames(test)[1] = "p_values"
test = data.frame(test[-c(9001,9002),])
colnames(test)[1] = "p_values"
ggplot(test, aes(x = p_values)) + geom_histogram()
ggplot(test, aes(x = p_values)) +
geom_histogram(binwidth=0.01)
View(multipleTests)
ggplot(test, aes(x = p_values)) +
geom_histogram(binwidth = 0.01, color="black", fill="lightblue")
View(p_values_m)
cap = "**Figure 5.** Histogram of p-values for generated from our simulation"
p_valuesHist = data.frame(p_values_m[-c(1:10),] %>% c(9000,1))
colnames(p_valuesHist)[1] = "p_values"
p_valuesHist = data.frame(p_valuesHist[-c(9001,9002),])
colnames(p_valuesHist)[1] = "p_values"
ggplot(p_valuesHist, aes(x = p_values)) +
geom_histogram(binwidth = 0.01, color = "black", fill = "lightblue")
cap = "**Figure 5.** Histogram of p-values for generated from our simulation"
p_valuesHist = data.frame(p_values_m[-c(1:10),] %>% c(9000,1))
colnames(p_valuesHist)[1] = "p_values"
p_valuesHist = data.frame(p_valuesHist[-c(9001,9002),])
colnames(p_valuesHist)[1] = "p_values"
ggplot(p_valuesHist, aes(x = p_values)) +
geom_histogram(binwidth = 0.01, color = "black", fill = "lightblue")+
ggtitle("Histogram of p-values for generated from our simulation")
View(multipleTests)
cap = '**Figure 2.** Estimated average annual electricity usage in khw/home for
each of 10 census divisions.'
kwh %>%
arrange( desc(est) ) %>%
mutate( div = factor(as.character(division), as.character(division) ) ) %>%
ggplot( aes(x = div, y = est) ) +
geom_point() +
geom_errorbar( aes(ymin = lwr, ymax = upr)) +
coord_flip() +
theme_bw() +
ylab('kwh/home') +
xlab('')
source('./ps3_q1.R')
cap = '**Table 2.** Average annual electricity utilization by Census Division
in kwh/home.'
# Multiplier for 95% CI
m = qnorm(.975)
# Pretty printing
pwc = function(x) format(round(x), big.mark = ',')
kwh %>%
arrange( desc(est) ) %>%
transmute(
`Census Division` = division,
`Average Electricity Usage, kwh/home (95% CI)` =
sprintf('%s, (%s - %s)', pwc(est), pwc(est - m*se), pwc(est + m*se) )
) %>%
knitr::kable( align = 'r', caption = cap)
cap = '**Figure 2.** Estimated average annual electricity usage in khw/home for
each of 10 census divisions.'
kwh %>%
arrange( desc(est) ) %>%
mutate( div = factor(as.character(division), as.character(division) ) ) %>%
ggplot( aes(x = div, y = est) ) +
geom_point() +
geom_errorbar( aes(ymin = lwr, ymax = upr)) +
coord_flip() +
theme_bw() +
ylab('kwh/home') +
xlab('')
cap = '**Table 3.** Average electricity utilization in kwh per home for urban
and rural areas witihin each census division.'
# Order by simple average usage
kwh_div_urban = kwh_div_urban %>%
group_by(division) %>%
mutate(div_avg = mean(est)) %>%
ungroup() %>%
arrange( desc(div_avg) ) %>%
mutate( div = as.character(division),
div = factor(div, levels = unique(div) )
)
# Table
kwh_div_urban %>%
ungroup() %>%
transmute(
`Census Division` = div,
`Average Electricity Usage, kwh/home (95% CI)` =
sprintf('%s, (%6s - %6s)', pwc(est), pwc(est - m*se), pwc(est + m*se)),
Rurality = ifelse(urban, 'Urban, kwh/home (95% CI)',
'Rural, kwh/home (95% CI)')
) %>%
spread(Rurality, `Average Electricity Usage, kwh/home (95% CI)` ) %>%
knitr::kable( align  = 'r', cap = cap)
rmarkdown::render('ps3.Rmd',
output_file = paste0("index.html"))
rmarkdown::render('ps3.Rmd',
output_file = paste0("index.html"))
