scale_x_continuous("rho", labels = as.character(rhoVec), breaks = rhoVec) +
ggtitle(TeX("$\\sigma = 1$"))
ggplot(filteredData, aes(fill = method, y = est, x = rho)) +
geom_bar(position ="dodge", stat="identity") +
geom_errorbar( aes( ymin = lwr, ymax = upr),
col = 'darkslategrey', position=position_dodge()) +
scale_x_continuous("rho", labels = as.character(rhoVec), breaks = rhoVec) +
ggtitle(TeX("$\\sigma = 1$")) +
theme(plot.title = element_text(hjust = 0.5))
iteration = 1;
for(metrics in metricList)
{
filteredData = results_q4b %>%
filter(sigma == sigmaVec[1], metric == metrics)
p1 = ggplot(filteredData, aes(fill = method, y = est, x = rho)) +
geom_bar(position ="dodge", stat="identity") +
geom_errorbar( aes( ymin = lwr, ymax = upr),
col = 'darkslategrey', position=position_dodge()) +
scale_x_continuous("rho", labels = as.character(rhoVec), breaks = rhoVec) +
ggtitle(TeX("$\\sigma = 1$")) +
theme(plot.title = element_text(hjust = 0.5))
filteredData = results_q4b %>%
filter(sigma == sigmaVec[2], metric == metrics)
p2 = ggplot(filteredData, aes(fill = method, y = est, x = rho)) +
geom_bar(position ="dodge", stat="identity") +
geom_errorbar( aes( ymin = lwr, ymax = upr),
col = 'darkslategrey', position=position_dodge()) +
scale_x_continuous("rho", labels = as.character(rhoVec), breaks = rhoVec)
filteredData = results_q4b %>%
filter(sigma == sigmaVec[3], metric == metrics)
p3 = ggplot(filteredData, aes(fill = method, y = est, x = rho)) +
geom_bar(position ="dodge", stat="identity") +
geom_errorbar( aes( ymin = lwr, ymax = upr),
col = 'darkslategrey', position=position_dodge()) +
scale_x_continuous("rho", labels = as.character(rhoVec), breaks = rhoVec)
assign(paste0("Chart",iteration),
grid.arrange(p1, p2, p3, nrow = 3,
top = paste0(toupper(metrics), " Estimates")))
# Increment our iterator
iteration = iteration + 1
}
grid.arrange(Chart1, Chart2, nrow = 2)
grid.arrange(Chart3, Chart4, nrow = 2)
TeX("$\\sigma = 1$")
paste0(TeX("$\\sigma = 1$"))
TeX("$\\sigma = 1$")
help(TeX)
iteration = 1;
for(metrics in metricList)
{
filteredData = results_q4b %>%
filter(sigma == sigmaVec[1], metric == metrics)
p1 = ggplot(filteredData, aes(fill = method, y = est, x = rho)) +
geom_bar(position ="dodge", stat="identity") +
geom_errorbar( aes( ymin = lwr, ymax = upr),
col = 'darkslategrey', position=position_dodge()) +
scale_x_continuous("rho", labels = as.character(rhoVec), breaks = rhoVec) +
ggtitle(TeX(paste0("$\\sigma = ", sigmaVec[1], "$"))) +
theme(plot.title = element_text(hjust = 0.5))
filteredData = results_q4b %>%
filter(sigma == sigmaVec[2], metric == metrics)
p2 = ggplot(filteredData, aes(fill = method, y = est, x = rho)) +
geom_bar(position ="dodge", stat="identity") +
geom_errorbar( aes( ymin = lwr, ymax = upr),
col = 'darkslategrey', position=position_dodge()) +
scale_x_continuous("rho", labels = as.character(rhoVec), breaks = rhoVec) +
ggtitle(TeX(paste0("$\\sigma = ", sigmaVec[2], "$"))) +
theme(plot.title = element_text(hjust = 0.5))
filteredData = results_q4b %>%
filter(sigma == sigmaVec[3], metric == metrics)
p3 = ggplot(filteredData, aes(fill = method, y = est, x = rho)) +
geom_bar(position ="dodge", stat="identity") +
geom_errorbar( aes( ymin = lwr, ymax = upr),
col = 'darkslategrey', position=position_dodge()) +
scale_x_continuous("rho", labels = as.character(rhoVec), breaks = rhoVec) +
ggtitle(TeX(paste0("$\\sigma = ", sigmaVec[3], "$"))) +
theme(plot.title = element_text(hjust = 0.5))
assign(paste0("Chart",iteration),
grid.arrange(p1, p2, p3, nrow = 3,
top = paste0(toupper(metrics), " Estimates")))
# Increment our iterator
iteration = iteration + 1
}
grid.arrange(Chart1, Chart2, nrow = 2)
grid.arrange(Chart3, Chart4, nrow = 2)
View(results_q4b)
## Problem Set 4 Question 1
##
##
## In this question we work with the 'mtcars' dataset and calculate univariate
## regressions written in data.table and dplyr. We also write functions that
## compute univariate regressions based on arbitrary independent, dependent,
## and grouping variables.
##
## This file is part of a set of files consisting of:
## ps4.pdf , ps4.Rmd , ps4_q1.R , ps4_q2_funcs.R , ps4_q2a.R , ps4_q2b.R ,
## ps4_q2c.R, run_ps4_q2b.pbs , run_ps4_q2c.pbs, ps4_q2b.Rout ,
## ps4_q2c-X.Rout (X = 1, 2, 4), ps4_q3.sas , ps4_q3c.csv , ps4_q3d.csv
##
## Author: Israel Diego (israeldi@umich.edu)
## Due: December 10, 2018
rm(list = ls())
# Packages
# install.packages('Lahman')
#install.packages('RSQLite')
library(tidyverse)
library(dbplyr)
library(Lahman)
# QUESTION 1 -----------------------------------------------------------------
# Write an SQL query to construct a table showing the all-time leader in hits
# (“H” from the “batting” table) for each birth country (“birthCountry” in the
# “master” table).
#
# An all-time leader is the player (“playerID”) with the most total hits across
# all rows (e.g. seasons/stints). Limit your table to players/countries with at
# least 200 hits and order the table by descending number of hits.
#
# Create a nicely formatted table with the following columns as your final
# output: Player (nameFirst nameLast), Debut (debut),
#         Country of Birth (birthCountry), Hits (H)
# Create a local SQLlite database of the Lahman data
lahman = lahman_sqlite()
# Query the batting table
# Group By player id and sum rows for hits
hits = lahman %>%
tbl(sql('
SELECT firstName || " " || lastName as Name,
strftime("%m-%d-%Y", Debut) as Debut, birthCountry, max(Hits) as Hits
FROM(
SELECT a.playerID, b.nameFirst firstName, b.nameLast lastName,
b.debut Debut,
b.birthCountry birthCountry, sum(H) as Hits
FROM batting a
INNER JOIN master b ON a.playerID = b.playerID
GROUP BY a.playerID
HAVING Hits >= 200
)
GROUP BY birthCountry
ORDER BY -Hits')) %>% collect()
View(hits)
hits = lahman %>%
tbl(sql('
SELECT firstName || " " || lastName as Name,
strftime("%m-%d-%Y", Debut) as Debut, birthCountry, max(Hits) as Hits
FROM(
SELECT a.playerID, m.nameFirst firstName, m.nameLast lastName,
m.debut Debut,
m.birthCountry birthCountry, sum(H) as Hits
FROM batting bat
INNER JOIN master m ON bat.playerID = m.playerID
GROUP BY bat.playerID
HAVING Hits >= 200
)
GROUP BY birthCountry
ORDER BY -Hits')) %>% collect()
hits = lahman %>%
tbl(sql('
SELECT firstName || " " || lastName as Name,
strftime("%m-%d-%Y", Debut) as Debut, birthCountry, max(Hits) as Hits
FROM(
SELECT bat.playerID, m.nameFirst firstName, m.nameLast lastName,
m.debut Debut,
m.birthCountry birthCountry, sum(H) as Hits
FROM batting bat
INNER JOIN master m ON bat.playerID = m.playerID
GROUP BY bat.playerID
HAVING Hits >= 200
)
GROUP BY birthCountry
ORDER BY -Hits')) %>% collect()
allTimeHits = lahman %>%
tbl(sql('
SELECT firstName || " " || lastName as Name,
strftime("%m-%d-%Y", Debut) as Debut, birthCountry, max(Hits) as Hits
FROM(
SELECT bat.playerID, m.nameFirst firstName, m.nameLast lastName,
m.debut Debut,
m.birthCountry birthCountry, sum(H) as Hits
FROM batting bat
INNER JOIN master m ON bat.playerID = m.playerID
GROUP BY bat.playerID
HAVING Hits >= 200
)
GROUP BY birthCountry
ORDER BY -Hits')) %>% collect()
View(allTimeHits)
knitr::opts_chunk$set(echo = FALSE)
source('./ps4_q1.R')
View(allTimeHits)
cap = '**Table 1.** All-time leaders most total career hits for each birth
country'
allTimeHits %>%
knitr::kable( align = 'r', caption = cap)
source('./ps4_q2b.R')
library(ggplot2)
library(grid)
library(gridExtra)
library(latex2exp)
# Use data to compute confidence intervals of our estimates to be displayed in
# our bar charts
m = qnorm(.975)
results_q4b = results_q4b %>%
mutate(lwr = est - m*se, upr = est + m*se)
# Displaying results in bar charts, displaying each metric on separate subplots
iteration = 1;
for(metrics in metricList)
{
# Plot for sigma = 0.25
filteredData = results_q4b %>%
filter(sigma == sigmaVec[1], metric == metrics)
p1 = ggplot(filteredData, aes(fill = method, y = est, x = rho)) +
geom_bar(position ="dodge", stat="identity") +
geom_errorbar( aes( ymin = lwr, ymax = upr),
col = 'darkslategrey', position=position_dodge()) +
scale_x_continuous("rho", labels = as.character(rhoVec), breaks = rhoVec) +
ggtitle(TeX(paste0("$\\sigma = ", sigmaVec[1], "$"))) +
theme(plot.title = element_text(hjust = 0.5))
# Plot for sigma = 0.50
filteredData = results_q4b %>%
filter(sigma == sigmaVec[2], metric == metrics)
p2 = ggplot(filteredData, aes(fill = method, y = est, x = rho)) +
geom_bar(position ="dodge", stat="identity") +
geom_errorbar( aes( ymin = lwr, ymax = upr),
col = 'darkslategrey', position=position_dodge()) +
scale_x_continuous("rho", labels = as.character(rhoVec), breaks = rhoVec) +
ggtitle(TeX(paste0("$\\sigma = ", sigmaVec[2], "$"))) +
theme(plot.title = element_text(hjust = 0.5))
# Plot for sigma = 1.0
filteredData = results_q4b %>%
filter(sigma == sigmaVec[3], metric == metrics)
p3 = ggplot(filteredData, aes(fill = method, y = est, x = rho)) +
geom_bar(position ="dodge", stat="identity") +
geom_errorbar( aes( ymin = lwr, ymax = upr),
col = 'darkslategrey', position=position_dodge()) +
scale_x_continuous("rho", labels = as.character(rhoVec), breaks = rhoVec) +
ggtitle(TeX(paste0("$\\sigma = ", sigmaVec[3], "$"))) +
theme(plot.title = element_text(hjust = 0.5))
# Put all three plots together
assign(paste0("Chart",iteration),
grid.arrange(p1, p2, p3, nrow = 3,
top = paste0(toupper(metrics), " Estimates")))
# Increment our iterator
iteration = iteration + 1
}
# Put Charts together, where we have 4 charts total corresponding to the 4
# metrics we computed in our simulation
grid.arrange(Chart1, Chart2, Chart3, Chart4, nrow = 2, ncol = 2)
# Use data to compute confidence intervals of our estimates to be displayed in
# our bar charts
m = qnorm(.975)
results_q4b = results_q4b %>%
mutate(lwr = est - m*se, upr = est + m*se)
# Displaying results in bar charts, displaying each metric on separate subplots
iteration = 1;
for(metrics in metricList)
{
# Plot for sigma = 0.25
filteredData = results_q4b %>%
filter(sigma == sigmaVec[1], metric == metrics)
p1 = ggplot(filteredData, aes(fill = method, y = est, x = rho)) +
geom_bar(position ="dodge", stat="identity") +
geom_errorbar( aes( ymin = lwr, ymax = upr),
col = 'darkslategrey', position=position_dodge()) +
scale_x_continuous("rho", labels = as.character(rhoVec), breaks = rhoVec) +
ggtitle(TeX(paste0("$\\sigma = ", sigmaVec[1], "$"))) +
theme(plot.title = element_text(hjust = 0.5))
# Plot for sigma = 0.50
filteredData = results_q4b %>%
filter(sigma == sigmaVec[2], metric == metrics)
p2 = ggplot(filteredData, aes(fill = method, y = est, x = rho)) +
geom_bar(position ="dodge", stat="identity") +
geom_errorbar( aes( ymin = lwr, ymax = upr),
col = 'darkslategrey', position=position_dodge()) +
scale_x_continuous("rho", labels = as.character(rhoVec), breaks = rhoVec) +
ggtitle(TeX(paste0("$\\sigma = ", sigmaVec[2], "$"))) +
theme(plot.title = element_text(hjust = 0.5))
# Plot for sigma = 1.0
filteredData = results_q4b %>%
filter(sigma == sigmaVec[3], metric == metrics)
p3 = ggplot(filteredData, aes(fill = method, y = est, x = rho)) +
geom_bar(position ="dodge", stat="identity") +
geom_errorbar( aes( ymin = lwr, ymax = upr),
col = 'darkslategrey', position=position_dodge()) +
scale_x_continuous("rho", labels = as.character(rhoVec), breaks = rhoVec) +
ggtitle(TeX(paste0("$\\sigma = ", sigmaVec[3], "$"))) +
theme(plot.title = element_text(hjust = 0.5))
# Put all three plots together
assign(paste0("Chart",iteration),
grid.arrange(p1, p2, p3, nrow = 3,
top = paste0(toupper(metrics), " Estimates")))
# Increment our iterator
iteration = iteration + 1
}
Chart1
grid.arrange(Chart1,1,1)
grid.arrange(Chart1,nrow = 1,ncol = 1)
# Use data to compute confidence intervals of our estimates to be displayed in
# our bar charts
m = qnorm(.975)
results_q4b = results_q4b %>%
mutate(lwr = est - m*se, upr = est + m*se)
# Displaying results in bar charts, displaying each metric on separate subplots
iteration = 1;
for(metrics in metricList)
{
# Plot for sigma = 0.25
filteredData = results_q4b %>%
filter(sigma == sigmaVec[1], metric == metrics)
p1 = ggplot(filteredData, aes(fill = method, y = est, x = rho)) +
geom_bar(position ="dodge", stat="identity") +
geom_errorbar( aes( ymin = lwr, ymax = upr),
col = 'darkslategrey', position=position_dodge()) +
scale_x_continuous("rho", labels = as.character(rhoVec), breaks = rhoVec) +
ggtitle(TeX(paste0("$\\sigma = ", sigmaVec[1], "$"))) +
theme(plot.title = element_text(hjust = 0.5))
# Plot for sigma = 0.50
filteredData = results_q4b %>%
filter(sigma == sigmaVec[2], metric == metrics)
p2 = ggplot(filteredData, aes(fill = method, y = est, x = rho)) +
geom_bar(position ="dodge", stat="identity") +
geom_errorbar( aes( ymin = lwr, ymax = upr),
col = 'darkslategrey', position=position_dodge()) +
scale_x_continuous("rho", labels = as.character(rhoVec), breaks = rhoVec) +
ggtitle(TeX(paste0("$\\sigma = ", sigmaVec[2], "$"))) +
theme(plot.title = element_text(hjust = 0.5))
# Plot for sigma = 1.0
filteredData = results_q4b %>%
filter(sigma == sigmaVec[3], metric == metrics)
p3 = ggplot(filteredData, aes(fill = method, y = est, x = rho)) +
geom_bar(position ="dodge", stat="identity") +
geom_errorbar( aes( ymin = lwr, ymax = upr),
col = 'darkslategrey', position=position_dodge()) +
scale_x_continuous("rho", labels = as.character(rhoVec), breaks = rhoVec) +
ggtitle(TeX(paste0("$\\sigma = ", sigmaVec[3], "$"))) +
theme(plot.title = element_text(hjust = 0.5))
# Put all three plots together
assign(paste0("Chart",iteration),
grid.arrange(p1, p2, p3, nrow = 3,
top = paste0(toupper(metrics), " Estimates")))
# Increment our iterator
iteration = iteration + 1
}
source('./ps4_q2a.R')
source('./ps4_q2a.R')
knitr::opts_chunk$set(echo = FALSE)
library(ggplot2)
library(grid)
library(gridExtra)
library(latex2exp)
source('./ps4_q2c.R')
source('./ps4_q2c.R')
# Use data to compute confidence intervals of our estimates to be displayed in our bar charts
m = qnorm(.975)
results_q4c = results_q4c %>%
mutate(lwr = est - m*se, upr = est + m*se)
# Displaying results in bar charts, displaying each metric on separate subplots
iteration = 1
for(metrics in metricList)
{
# Plot for sigma = 1.0
filteredData = results_q4c %>%
filter(metric == metrics)
p1 = ggplot(filteredData, aes(fill = method, y = est, x = rho)) +
geom_bar(position ="dodge", stat="identity") +
geom_errorbar( aes( ymin = lwr, ymax = upr),
col = 'darkslategrey', position=position_dodge()) +
scale_x_continuous("rho", labels = as.character(rhoVec), breaks = rhoVec) +
ggtitle(TeX(paste0("$\\sigma = 1$"))) +
theme(plot.title = element_text(hjust = 0.5))
# Put all three plots together
assign(paste0("Chart",iteration),
grid.arrange(p1, nrow = 1, ncol = 1,
top = paste0(toupper(metrics), " Estimates")))
# Increment our iterator
iteration = iteration + 1
}
names(knitr::knit_engines$get())
library(SASmarkdown)
install.packages("SASmarkdown")
library(SASmarkdown)
rmarkdown::render('ps4.Rmd',
output_file = paste0("index.html"))
## Problem Set 4 Question 1
##
##
## In this question we work with the 'mtcars' dataset and calculate univariate
## regressions written in data.table and dplyr. We also write functions that
## compute univariate regressions based on arbitrary independent, dependent,
## and grouping variables.
##
## This file is part of a set of files consisting of:
## ps4.pdf , ps4.Rmd , ps4_q1.R , ps4_q2_funcs.R , ps4_q2a.R , ps4_q2b.R ,
## ps4_q2c.R, run_ps4_q2b.pbs , run_ps4_q2c.pbs, ps4_q2b.Rout ,
## ps4_q2c-X.Rout (X = 1, 2, 4), ps4_q3.sas , ps4_q3c.csv , ps4_q3d.csv
##
## Author: Israel Diego (israeldi@umich.edu)
## Due: December 10, 2018
rm(list = ls())
# Packages
install.packages('Lahman')
install.packages('RSQLite')
library(tidyverse)
library(dbplyr)
library(Lahman)
# QUESTION 1 -----------------------------------------------------------------
# Write an SQL query to construct a table showing the all-time leader in hits
# (“H” from the “batting” table) for each birth country (“birthCountry” in the
# “master” table).
#
# An all-time leader is the player (“playerID”) with the most total hits across
# all rows (e.g. seasons/stints). Limit your table to players/countries with at
# least 200 hits and order the table by descending number of hits.
#
# Create a nicely formatted table with the following columns as your final
# output: Player (nameFirst nameLast), Debut (debut),
#         Country of Birth (birthCountry), Hits (H)
# Create a local SQLlite database of the Lahman data
lahman = lahman_sqlite()
allTimeHits = lahman %>%
tbl(sql('
SELECT firstName || " " || lastName as Name,
strftime("%m-%d-%Y", Debut) as Debut, birthCountry, max(Hits) as Hits
FROM(
SELECT bat.playerID, m.nameFirst firstName, m.nameLast lastName,
m.debut Debut,
m.birthCountry birthCountry, sum(H) as Hits
FROM batting bat
INNER JOIN master m ON bat.playerID = m.playerID
GROUP BY bat.playerID
HAVING Hits >= 200
)
GROUP BY birthCountry
ORDER BY -Hits')) %>% collect()
View(lahman)
lahman %>% tbl("BATTING")
lahman %>% tbl()
lahman %>% tbl("BATTING")
batting = lahman %>% tbl("BATTING")
View(batting)
typeof(batting)
allTimeHits = lahman %>%
tbl(sql('
SELECT firstName || " " || lastName as Name,
strftime("%m-%d-%Y", Debut) as Debut, birthCountry, max(Hits) as Hits
FROM(
SELECT bat.playerID, m.nameFirst firstName, m.nameLast lastName,
m.debut Debut,
m.birthCountry birthCountry, sum(H) as Hits
FROM batting bat
INNER JOIN master m ON bat.playerID = m.playerID
GROUP BY bat.playerID
HAVING Hits >= 200
)
GROUP BY birthCountry
ORDER BY -Hits')) %>% collect()
## Problem Set 4 Question 1
##
##
## In this question we work with the 'mtcars' dataset and calculate univariate
## regressions written in data.table and dplyr. We also write functions that
## compute univariate regressions based on arbitrary independent, dependent,
## and grouping variables.
##
## This file is part of a set of files consisting of:
## ps4.pdf , ps4.Rmd , ps4_q1.R , ps4_q2_funcs.R , ps4_q2a.R , ps4_q2b.R ,
## ps4_q2c.R, run_ps4_q2b.pbs , run_ps4_q2c.pbs, ps4_q2b.Rout ,
## ps4_q2c-X.Rout (X = 1, 2, 4), ps4_q3.sas , ps4_q3c.csv , ps4_q3d.csv
##
## Author: Israel Diego (israeldi@umich.edu)
## Due: December 10, 2018
rm(list = ls())
# Packages
install.packages('Lahman')
install.packages('RSQLite')
install.packages('dbplyr')
install.packages('tidyverse')
library(tidyverse)
library(dbplyr)
library(Lahman)
allTimeHits = lahman %>%
tbl(sql('
SELECT firstName || " " || lastName as Name,
strftime("%m-%d-%Y", Debut) as Debut, birthCountry, max(Hits) as Hits
FROM(
SELECT bat.playerID, m.nameFirst firstName, m.nameLast lastName,
m.debut Debut,
m.birthCountry birthCountry, sum(H) as Hits
FROM batting bat
INNER JOIN master m ON bat.playerID = m.playerID
GROUP BY bat.playerID
HAVING Hits >= 200
)
GROUP BY birthCountry
ORDER BY -Hits')) %>% collect()
lahman = lahman_sqlite()
allTimeHits = lahman %>%
tbl(sql('
SELECT firstName || " " || lastName as Name,
strftime("%m-%d-%Y", Debut) as Debut, birthCountry, max(Hits) as Hits
FROM(
SELECT bat.playerID, m.nameFirst firstName, m.nameLast lastName,
m.debut Debut,
m.birthCountry birthCountry, sum(H) as Hits
FROM batting bat
INNER JOIN master m ON bat.playerID = m.playerID
GROUP BY bat.playerID
HAVING Hits >= 200
)
GROUP BY birthCountry
ORDER BY -Hits')) %>% collect()
typeof(allTimeHits)
View(allTimeHits)
